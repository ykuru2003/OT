#%%===================================================
# ï¼‘ ãƒ‡ãƒ¼ã‚¿ã®ç†è§£ã¨EDA
# ====================================================
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#%%------------------------------------------
# 1-0 ç”»åƒä¿å­˜é–¢æ•°ã®ä½œæˆ
#--------------------------------------------
def save_plot_from_title(folder='../outputs'):
    """ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãã®ã¾ã¾ãƒ•ã‚¡ã‚¤ãƒ«åã«ã—ã¦ä¿å­˜"""
    os.makedirs(folder, exist_ok=True)
    
    # ç¾åœ¨ã®ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
    title = plt.gca().get_title()
    if not title:
        title = 'untitled_plot'
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’çµ„ã¿ç«‹ã¦ã¦ä¿å­˜
    filename = f"{title}.png"
    path = os.path.join(folder, filename)
    plt.savefig(path, dpi=300, bbox_inches='tight')
    print(f"âœ… Saved: {path}")

#%%------------------------------------------
# 1-1 ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
#--------------------------------------------
data = pd.read_csv("../data/ett.csv", parse_dates=["date"], encoding="utf-8")
data = data.sort_values('date')
num_cols = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']
print(data.head(10))
print(data.shape)

#%%------------------------------------------
# 1-2 åŸºæœ¬çµ±è¨ˆé‡ã®ç¢ºèªã¨å¯è¦–åŒ–
#--------------------------------------------

#åŸºæœ¬çµ±è¨ˆé‡ã®ç¢ºèª
print(data.describe())        # åŸºæœ¬çµ±è¨ˆé‡
print(data.info())            # ãƒ‡ãƒ¼ã‚¿å‹ã‚„æ¬ ææƒ…å ±
print(data.isnull().sum())    # æ¬ æå€¤ã®åˆè¨ˆ

#åŸºæœ¬çµ±è¨ˆé‡ã®å¯è¦–åŒ–
plt.figure(figsize=(12, 6))
sns.boxplot(data=data[num_cols])
plt.title('Boxplot of Numeric Columns', fontsize=14)
plt.ylabel('Value')
plt.xticks(rotation=30) 
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
save_plot_from_title()
plt.show()

#%%------------------------------------------
# 1-3 ç›®çš„å¤‰æ•°ã®å¯è¦–åŒ–
#--------------------------------------------
plt.figure(figsize=(12, 5))
plt.plot(data['date'], data['OT'], color='steelblue')
plt.title('Overview of OT (Oil Temperature)')
plt.xlabel('Date')
plt.ylabel('Oil Temperature (OT)')
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
save_plot_from_title()
plt.show()

#%%------------------------------------------
# 1-4 è‡ªå·±ç›¸é–¢ã®å¯è¦–åŒ–
#--------------------------------------------
plt.figure(figsize=(12, 8))

for col in num_cols:
    autocorr = [data[col].autocorr(lag=i) for i in range(1, 500)]
    plt.plot(range(1, 500), autocorr, label=col)

plt.title('Autocorrelation of All Variables')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.legend(loc='upper right')
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
save_plot_from_title()
plt.show()

#%%------------------------------------------
# 1-5 å¤‰æ•°ã®åˆ†å¸ƒã®å¯è¦–åŒ–
#--------------------------------------------
sns.set_theme(style="whitegrid")

cols = 3
rows = -(-len(num_cols) // cols) 

fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
axes = axes.flatten()

for i, col in enumerate(num_cols):
    if col not in data.columns:
        continue

    sns.histplot(data[col].dropna(), bins='fd', kde=True,
                 ax=axes[i], color='skyblue', edgecolor='black')

    axes[i].set_title(col, fontsize=11)
    axes[i].set_xlabel('')
    axes[i].set_ylabel('Frequency')

# ä½™ã£ãŸã‚°ãƒ©ãƒ•æ ã‚’éè¡¨ç¤º
for ax in axes[len(num_cols):]:
    ax.set_visible(False)

plt.title('Distributions of Numeric Variables', fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.96])
save_plot_from_title()
plt.show()

#%%------------------------------------------
# 1-6 ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã®ç›¸é–¢
#--------------------------------------------

#ç›¸é–¢ä¿‚æ•°ã‚’æ±‚ã‚ã‚‹
target_col = 'OT'
numeric_features = [col for col in num_cols if col != target_col]

corrs = data[numeric_features].corrwith(data[target_col], method='pearson')
corrs = corrs.sort_values(ascending=False)
print("Correlation with OT:\n", corrs)

#ç›¸é–¢è¡Œåˆ—ã®ä½œæˆ
numeric_data = data.select_dtypes(include=['number'])
corr_matrix = numeric_data.corr()

plt.figure(figsize=(14, 12))
sns.heatmap(
    corr_matrix,
    annot=True,             
    fmt='.2f',               
    cmap='coolwarm',
    vmin=-1, vmax=1,         
    square=True,           
    linewidths=0.5,     
    annot_kws={"size": 8}
)

plt.title('Correlation Matrix of Numeric Features', fontsize=16)
plt.tight_layout()
save_plot_from_title()
plt.show()

#%%------------------------------------------
# 1-7 å‘¨æœŸæ€§ã®å¯è¦–åŒ–
#--------------------------------------------
from statsmodels.tsa.seasonal import seasonal_decompose

# æ™‚ç³»åˆ—åˆ†è§£
result = seasonal_decompose(data['OT'], model='additive', period=24*30)

# åˆ†è§£ã•ã‚ŒãŸæˆåˆ†ã‚’å–å¾—
observed = result.observed
trend = result.trend
seasonal = result.seasonal
resid = result.resid

# æ‰‹å‹•ã§4æ®µãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True, gridspec_kw={'height_ratios': [2, 1.5, 1, 1.5]})

axes[0].plot(observed, color='steelblue')
axes[0].set_title('Original (Observed Data)', fontsize=13)
axes[0].grid(True, linestyle='--', alpha=0.5)

axes[1].plot(trend, color='orange')
axes[1].set_title('Trend (Long-term Movement)', fontsize=13)
axes[1].grid(True, linestyle='--', alpha=0.5)

axes[2].plot(seasonal, color='green')
axes[2].set_title('Seasonal (Periodic Pattern)', fontsize=13)
axes[2].grid(True, linestyle='--', alpha=0.5)

axes[3].plot(resid, color='gray')
axes[3].set_title('Residual (Irregular / Random)', fontsize=13)
axes[3].grid(True, linestyle='--', alpha=0.5)

plt.xlabel('Time (hour index)')
plt.tight_layout(pad=2)
plt.show()

#%%------------------------------------------
# 1-8 æ—¥å‘¨æœŸã®å¯è¦–åŒ–
#--------------------------------------------
from statsmodels.tsa.seasonal import seasonal_decompose

# æ—¥å‘¨æœŸã§åˆ†è§£
data['date'] = pd.to_datetime(data['date'])
data = data.set_index('date').asfreq('H')
result = seasonal_decompose(data['OT'], model='additive', period=24)
trend = result.trend.dropna().reset_index()

# ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†ã‚’ã€Œæ—¥ã”ã¨ã€ã«å¹³å‡åŒ–
trend['hour'] = trend['date'].dt.hour
daily_trend = trend.groupby('hour')['trend'].mean()

# å¯è¦–åŒ–
plt.figure(figsize=(10, 5))
plt.plot(daily_trend.index, daily_trend.values, marker='o', color='darkorange')
plt.title('Average Hourly Trend Component (from Decomposition)', fontsize=14)
plt.xlabel('Hour of Day')
plt.ylabel('Average Trend Value')
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
save_plot_from_title()
plt.show()

#%%===================================================
# 2 ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
# ====================================================

#æ¬ æå€¤ã¯ç„¡ã—
#ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã‚’å…¥ã‚ŒãŸå¾Œã«ç•°å¸¸å€¤å‡¦ç†ã‚’è¡Œã†ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¯å¾Œè¿°ã™ã‚‹
#ç•°å¸¸å€¤å‡¦ç†ã¨ã—ã¦ã€Œæ¨™æº–åŒ–ã€ã€Œã‚¯ãƒªãƒƒãƒ—ã€ã‚’è¡Œã£ãŸ


#%%===================================================
# 3 ãƒ¢ãƒ‡ãƒ«è¨­å®šã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
# ====================================================

#%%------------------------------------------
# 3-1 ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã®è¿½åŠ 
#--------------------------------------------
import statsmodels.api as sm

#AICã¨BICã‚’ç”¨ã„ã¦ã€æœ€é©ãªãƒ•ãƒ¼ãƒªã‚¨æ¬¡æ•°ã‚’æ±‚ã‚ã‚‹

# æ™‚é–“è»¸
t = np.arange(len(data))
y = data['OT']

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
max_k = 10
periods = {
    "day": 24,
    "week":24*7,
    "month":24*30,
    "year": 24*365
}

# çµæœä¿å­˜ç”¨
results = []

# å„å‘¨æœŸã”ã¨ã«æœ€é©kã‚’æ¢ç´¢
for name, period in periods.items():
    aic_list = []
    bic_list = []
    
    for k in range(1, max_k + 1):
        # ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ç”Ÿæˆ
        X = pd.DataFrame({
            f'{name}_sin{k}': np.sin(2 * np.pi * k * t / period),
            f'{name}_cos{k}': np.cos(2 * np.pi * k * t / period)
        })
        X.index = y.index
        X = sm.add_constant(X)

        # å›å¸°
        model = sm.OLS(y, X).fit()

        # çµæœä¿å­˜
        aic_list.append(model.aic)
        bic_list.append(model.bic)

    # DataFrameåŒ–
    tmp_df = pd.DataFrame({
        'k': range(1, max_k + 1),
        'AIC': aic_list,
        'BIC': bic_list
    })
    
    # æœ€å°AIC/BIC
    best_k_aic = tmp_df.loc[tmp_df['AIC'].idxmin(), 'k']
    best_k_bic = tmp_df.loc[tmp_df['BIC'].idxmin(), 'k']

    results.append({
        'Period': name,
        'Best_k_AIC': best_k_aic,
        'Best_k_BIC': best_k_bic
    })

    # å¯è¦–åŒ–
    plt.figure(figsize=(7,4))
    plt.plot(tmp_df['k'], tmp_df['AIC'], marker='o', label='AIC')
    plt.plot(tmp_df['k'], tmp_df['BIC'], marker='s', label='BIC')
    plt.title(f'AIC/BIC by Fourier Order (Period = {name})')
    plt.xlabel('Fourier Order k')
    plt.ylabel('Information Criterion')
    plt.legend()
    plt.grid(True)
    plt.show()

# å…¨å‘¨æœŸã®çµæœã¾ã¨ã‚
result_df = pd.DataFrame(results)

print("=== æ—¥å‘¨æœŸã¨å¹´å‘¨æœŸãŠã‘ã‚‹æœ€é©ãƒ•ãƒ¼ãƒªã‚¨æ¬¡æ•° ===")
print(result_df)

#æœ€é©ãªkã®è¨­å®š
best_k = {
    "day": 2, #1ã§æœ€å°ã ã£ãŸãŒã€1ã®æ™‚ã«è‡ªå·±ç›¸é–¢ã«æ—¥å‘¨æœŸãŒæ®‹ã£ã¦ã„ãŸãŸã‚2ã§è¨­å®š
    "week":1, #7ã§æœ€å°ã ã£ãŸãŒã€å¤šé‡å…±ç·šæ€§ã¸ã®æ‡¸å¿µã‹ã‚‰1ã«è¨­å®š
    "month":2,
    "year": 1
}

#æœŸé–“ã®è¨­å®š
periods = {
    "day": 24,
    "week":24*7,
    "month":24*30,
    "year": 24*365
}

# data_fourier_ts ã®ä½œæˆ-
data_fourier_ts = pd.DataFrame()
data_fourier_ts.index = data.index

# æ™‚é–“è»¸
t = np.arange(len(data))

# ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã‚’ data_fourier_ts ã«è¿½åŠ 
for name, period in periods.items():
    k_opt = best_k[name]
    for k in range(1, k_opt + 1):
        data_fourier_ts[f'{name}_sin{k}'] = np.sin(2 * np.pi * k * t / period)
        data_fourier_ts[f'{name}_cos{k}'] = np.cos(2 * np.pi * k * t / period)

print("âœ… data_fourier_ts ã«ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
print([col for col in data_fourier_ts.columns if any(x in col for x in ['sin', 'cos'])])

#%%------------------------------------------
# 3-2 æ™‚ç³»åˆ—æ§‹é€ åŒ–
#--------------------------------------------

# æ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ
ts_features = pd.DataFrame(index=data.index)
ts_features['OT_lag1'] = data['OT'].shift(1)
ts_features['OT_lag24'] = data['OT'].shift(24)
ts_features['OT_ma24'] = data['OT'].shift(1).rolling(window=24).mean()

#data_fourier_tsã«çµ±åˆã™ã‚‹
data_fourier_ts = pd.concat([data_fourier_ts, ts_features], axis=1)

data_fourier_ts = data_fourier_ts.loc[:, ~data_fourier_ts.columns.duplicated()]


#ç¢ºèª
print(data_fourier_ts.columns)

#%%------------------------------------------
# 3-3 ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
#--------------------------------------------
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# æ¨™æº–åŒ–å¯¾è±¡ã®åˆ—ã‚’å®šç¾©
cols_from_data = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']
cols_from_ts_features = ['OT_lag1', 'OT_lag24','OT_ma24',]

# å¤–ç”Ÿå¤‰æ•°ã‚’æ¨™æº–åŒ–
scaled_data_part = pd.DataFrame(
    scaler.fit_transform(data[cols_from_data]),
    columns=[f"{c}_scaled" for c in cols_from_data],
    index=data.index
)

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ– ---
scaled_ts_part = pd.DataFrame(
    scaler.fit_transform(data_fourier_ts[cols_from_ts_features]),
    columns=[f"{c}_scaled" for c in cols_from_ts_features],
    index=data_fourier_ts.index
)

# --- æ¨™æº–åŒ–å¾Œã®å¤–ã‚Œå€¤ã‚’ Â±2 ã«ã‚¯ãƒªãƒƒãƒ— ---
scaled_data_part = scaled_data_part.clip(lower=-2, upper=2)
scaled_ts_part = scaled_ts_part.clip(lower=-2, upper=2)

# çµæœã‚’çµåˆ
data_scaled = scaled_data_part.join(scaled_ts_part, how='left')
data_fourier_ts = data_fourier_ts.join(data_scaled, how='left')

# æ¬ æã‚’å«ã‚€è¡Œã‚’å‰Šé™¤
data_fourier_ts = data_fourier_ts.dropna(subset=ts_features.columns)

#ç¢ºèª
print("âœ… æ¬ æã‚’å‰Šé™¤å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:", data_fourier_ts.shape)

# ç¢ºèª
print(data_fourier_ts.columns)
print(data_fourier_ts.head())

#%%------------------------------------------
# 3-4 ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã¨æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å›å¸°åˆ†æ
#--------------------------------------------
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
X = data_fourier_ts[[
    'day_sin1','day_cos1',
    'year_sin1','year_cos1',
    'OT_ma24_scaled'
]]
y = data_fourier_ts['OT_scaled']

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—é †ã«8:2ï¼‰
split_point = int(len(data_fourier_ts) * 0.8)
X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆtrainã®ã¿ï¼‰
model = LinearRegression()
model.fit(X_train, y_train)

# äºˆæ¸¬
data_fourier_ts.loc[X_train.index, 'OT_pred_linear'] = model.predict(X_train)
data_fourier_ts.loc[X_test.index, 'OT_pred_linear'] = model.predict(X_test)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
r2_train = r2_score(y_train, data_fourier_ts.loc[X_train.index, 'OT_pred_linear'])
rmse_train = np.sqrt(mean_squared_error(y_train, data_fourier_ts.loc[X_train.index, 'OT_pred_linear']))

# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
r2_test = r2_score(y_test, data_fourier_ts.loc[X_test.index, 'OT_pred_linear'])
rmse_test = np.sqrt(mean_squared_error(y_test, data_fourier_ts.loc[X_test.index, 'OT_pred_linear']))

print("âœ…  æ™‚ç³»åˆ—8:2åˆ†å‰²")
print(f"ğŸ”¹ RÂ²(å­¦ç¿’): {r2_train:.4f}")
print(f"ğŸ”¹ RMSE(å­¦ç¿’): {rmse_train:.4f}")
print(f"ğŸ”¹ RÂ²(æ¤œè¨¼): {r2_test:.4f}")
print(f"ğŸ”¹ RMSE(æ¤œè¨¼): {rmse_test:.4f}")


#%%------------------------------------------
# 3-5 Ridgeå›å¸°åˆ†æ
#--------------------------------------------
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# æ®‹å·®ã‚’ä½œæˆï¼ˆä¸€æ¬¡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®èª¤å·®ï¼‰
data_fourier_ts['residual_linear'] = data_fourier_ts['OT_scaled'] - data_fourier_ts['OT_pred_linear']

# ç‰¹å¾´é‡ï¼ˆ_scaledã§çµ‚ã‚ã‚‹åˆ—ã ã‘ã‚’ä½¿ç”¨ï¼‰
scaled_cols = [col for col in data_fourier_ts.columns if col.endswith('_scaled')]
X_ridge = data_fourier_ts[['HUFL_scaled', 'HULL_scaled', 'MUFL_scaled', 'MULL_scaled', 'LUFL_scaled', 'LULL_scaled']]
y_ridge = data_fourier_ts['residual_linear']

# æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆå‰8å‰²ã§å­¦ç¿’ã€å¾Œ2å‰²ã§æ¤œè¨¼ï¼‰
split_point = int(len(data_fourier_ts) * 0.8)
X_train, X_test = X_ridge.iloc[:split_point], X_ridge.iloc[split_point:]
y_train, y_test = y_ridge.iloc[:split_point], y_ridge.iloc[split_point:]

# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ãƒ»å­¦ç¿’
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train, y_train)

# train/test ãã‚Œãã‚Œã§äºˆæ¸¬
data_fourier_ts.loc[X_train.index, 'OT_pred_residual'] = ridge_model.predict(X_train)
data_fourier_ts.loc[X_test.index, 'OT_pred_residual'] = ridge_model.predict(X_test)

# è©•ä¾¡ï¼ˆå‚è€ƒï¼‰
r2_train = r2_score(y_train, data_fourier_ts.loc[X_train.index, 'OT_pred_residual'])
r2_test = r2_score(y_test, data_fourier_ts.loc[X_test.index, 'OT_pred_residual'])
rmse_train = np.sqrt(mean_squared_error(y_train, data_fourier_ts.loc[X_train.index, 'OT_pred_residual']))
rmse_test = np.sqrt(mean_squared_error(y_test, data_fourier_ts.loc[X_test.index, 'OT_pred_residual']))

print("âœ… Ridgeå›å¸°åˆ†æå®Œäº†")
print(f"ğŸ”¹ RÂ²(å­¦ç¿’): {r2_train:.4f}")
print(f"ğŸ”¹ RÂ²(æ¤œè¨¼): {r2_test:.4f}")
print(f"ğŸ”¹ RMSE(å­¦ç¿’): {rmse_train:.4f}")
print(f"ğŸ”¹ RMSE(æ¤œè¨¼): {rmse_test:.4f}")

#%%===================================================
# 4 ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨çµæœã®åˆ†æ
# ====================================================

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
#%%------------------------------------------
# 4-1 æœ€çµ‚äºˆæ¸¬å€¤ã®ç®—å‡º
#--------------------------------------------

# å‰åŠ8å‰²ã‚’å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã€å¾ŒåŠ2å‰²ã‚’äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹
# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
split_point = int(len(data_fourier_ts) * 0.8)
train = data_fourier_ts.iloc[:split_point].copy()
test = data_fourier_ts.iloc[split_point:].copy()
test['OT_pred_final'] = test['OT_pred_linear'] + test['OT_pred_residual']

#ã€€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
r2_final = r2_score(test['OT_scaled'], test['OT_pred_final'])
rmse_final = np.sqrt(mean_squared_error(test['OT_scaled'], test['OT_pred_final']))
mae_final = mean_absolute_error(test['OT_scaled'], test['OT_pred_final'])

print("âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è©•ä¾¡(æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿2å‰²)å®Œäº†")
print(f"æ±ºå®šä¿‚æ•° RÂ²(æ¤œè¨¼): {r2_final:.4f}")
print(f"RMSE(æ¤œè¨¼): {rmse_final:.4f}")
print(f"MAE(æ¤œè¨¼): {mae_final:.4f}")

#%%------------------------------------------
# 4-2 æœ€çµ‚äºˆæ¸¬å€¤ã®å¯è¦–åŒ–
#--------------------------------------------

plt.figure(figsize=(10, 4))
plt.plot(test.index, test['OT_scaled'], label='Actual', linewidth=1)
plt.plot(test.index, test['OT_pred_final'], label='Predicted (Final)', linestyle='--', linewidth=1.2)
plt.title('Actual vs Predicted (Final Model)')
plt.xlabel('Date')
plt.ylabel('OT_scaled')
plt.legend()
plt.grid(True)
plt.show()

#%%------------------------------------------
# 4-3 æ®‹å·®ã®æ¨ç§»ã®å¯è¦–åŒ–
#--------------------------------------------

plt.figure(figsize=(10, 3))
plt.plot(test.index, test['residual_linear'], label='Residual (Before Ridge)', color='gray', alpha=0.7)
plt.plot(test.index, test['OT_pred_residual'], label='Residual (Predicted by Ridge)', color='blue', alpha=0.7)
plt.title('Residuals Before and After Ridge Correction')
plt.xlabel('Date')
plt.ylabel('Residual')
plt.legend()
plt.grid(True)
plt.show()


#%%------------------------------------------
# 4-4 æ®‹å·®ã®è‡ªå·±ç›¸é–¢ãƒ»åè‡ªå·±ç›¸é–¢ã®å¯è¦–åŒ–
#--------------------------------------------
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Ridgeè£œæ­£å¾Œã®æ®‹å·®ã‚’ä½¿ç”¨
residuals = data_fourier_ts['OT_pred_residual']  # è‡ªåˆ†ã®åˆ—åã«åˆã‚ã›ã¦å¤‰æ›´ï¼

# ACFï¼ˆè‡ªå·±ç›¸é–¢é–¢æ•°ï¼‰
plt.figure(figsize=(10, 4))
plot_acf(residuals, lags=50)
plt.title("Autocorrelation Function (ACF) of Residuals")
plt.xlabel("Lag")
plt.ylabel("ACF")
plt.grid(True)
plt.tight_layout()
plt.show()

# PACFï¼ˆåè‡ªå·±ç›¸é–¢é–¢æ•°ï¼‰
plt.figure(figsize=(10, 4))
plot_pacf(residuals, lags=50, method='ywm')
plt.title("Partial Autocorrelation Function (PACF) of Residuals")
plt.xlabel("Lag")
plt.ylabel("PACF")
plt.grid(True)
plt.tight_layout()
plt.show()

#DWæ¤œå®šã®å®Ÿè¡Œ
from statsmodels.stats.stattools import durbin_watson
dw_stat = durbin_watson(data_fourier_ts['residual_linear'])
print('Durbin-Watson æ¤œå®šçµ±è¨ˆé‡:', dw_stat)


#%%------------------------------------------
# 4-5 ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–
#--------------------------------------------

# ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã¨æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å›å¸°åˆ†æã®é‡è¦åº¦
coef_linear = pd.DataFrame({
    'feature': X.columns,
    'coefficient': model.coef_
}).sort_values('coefficient', ascending=False)

print("ğŸ”¹ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã€‘")
print(coef_linear)

plt.figure(figsize=(6,4))
plt.barh(coef_linear['feature'], coef_linear['coefficient'])
plt.title('Linear Regression Coefficients')
plt.xlabel('Coefficient')
plt.gca().invert_yaxis()
plt.show()


# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã®é‡è¦åº¦
coef_ridge = pd.DataFrame({
    'feature': X_ridge.columns,
    'coefficient': ridge_model.coef_
}).sort_values('coefficient', ascending=False)

print("\nğŸ”¹ã€Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã€‘")
print(coef_ridge.head(15))  # ä¸Šä½15ä»¶ã®ã¿è¡¨ç¤º

plt.figure(figsize=(8,6))
plt.barh(coef_ridge['feature'].head(15), coef_ridge['coefficient'].head(15))
plt.title('Ridge Regression Coefficients (Top 15)')
plt.xlabel('Coefficient')
plt.gca().invert_yaxis()
plt.show()

#%%------------------------------------------
# 4-6 å›å¸°ãƒ¢ãƒ‡ãƒ«ã®på€¤ãƒ»æœ‰æ„æ€§ã®ç¢ºèª
#--------------------------------------------
import statsmodels.api as sm
import pandas as pd

# === â‘  ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ•ãƒ¼ãƒªã‚¨ï¼‹æ™‚ç³»åˆ—å¤‰æ•°ï¼‰ ===
X_train_sm = sm.add_constant(X_train)  # åˆ‡ç‰‡ã‚’è¿½åŠ 
ols_model = sm.OLS(y_train, X_train_sm).fit()

print("ğŸ”¹ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼šçµ±è¨ˆçš„è¦ç´„ã€‘")
print(ols_model.summary())

# ä¸»è¦ãªæŒ‡æ¨™ã ã‘æŠœãå‡ºã™è¡¨
summary_linear = pd.DataFrame({
    "feature": ['const'] + list(X_train.columns),
    "coef": ols_model.params.values,
    "std_err": ols_model.bse.values,
    "t_value": ols_model.tvalues.values,
    "p_value": ols_model.pvalues.values
})
print("\nã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ« ä¿‚æ•°ãƒ»på€¤ä¸€è¦§ã€‘")
print(summary_linear.sort_values("p_value").head(10))



# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«

X_ridge_sm = sm.add_constant(X_train)
ols_ridge_like = sm.OLS(y_train, X_ridge_sm).fit()

print("\nğŸ”¹ã€Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ç›¸å½“ã®çµ±è¨ˆè¦ç´„ã€‘")
print(ols_ridge_like.summary())

summary_ridge = pd.DataFrame({
    "feature": ['const'] + list(X_train.columns),
    "coef": ols_ridge_like.params.values,
    "std_err": ols_ridge_like.bse.values,
    "t_value": ols_ridge_like.tvalues.values,
    "p_value": ols_ridge_like.pvalues.values
})
print("\nã€Ridgeç›¸å½“ãƒ¢ãƒ‡ãƒ« ä¿‚æ•°ãƒ»på€¤ä¸€è¦§ã€‘")
print(summary_ridge.sort_values("p_value").head(10))

#%% ===================================================
# 5 æ”¹å–„ç­–ã®æ¤œè¨ã¨ãƒ¢ãƒ‡ãƒ«ã®å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
# =====================================================

#â‘ é€±å‘¨æœŸã¨æœˆå‘¨æœŸã‚‚å¤‰æ•°ã«è¨­å®šã™ã‚‹
#â‘¡ä¸€æ—¥å‰ã€ä¸€é€±é–“å‰ã€éå»ä¸€é€±é–“ã®ç§»å‹•å¹³å‡ã‚‚å¤‰æ•°ã«è¨­å®š
#å¤šé‡å…±ç·šæ€§ãŒæ‡¸å¿µã•ã‚Œã‚‹ã®ã§ã€æœ‰æ„æ€§ãŒä½ã„å¤‰æ•°ã¯é™¤å¤–

#%%------------------------------------------
# 5-1 å¤‰æ•°ã®å†è¨­å®šã¨ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ï¼‹æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å›å¸°åˆ†æ
#--------------------------------------------
X2 = data_fourier_ts[[
    'day_sin1', 'day_cos1','day_sin2','day_cos2',
    'week_sin1', 'week_cos1',
    'month_sin1', 'month_cos1',
    'year_sin1', 'year_cos1',
    'OT_ma24_scaled'
    ]]

y2 = data_fourier_ts['OT_scaled']

#ç›¸é–¢ä¿‚æ•°ã‚’èª¿ã¹ã‚‹
r1 = data_fourier_ts['OT_lag1_scaled'].corr(data_fourier_ts['OT_lag24_scaled'])
r2 = data_fourier_ts['OT_lag1_scaled'].corr(data_fourier_ts['OT_ma24_scaled'])
r3 = data_fourier_ts['OT_lag24_scaled'].corr(data_fourier_ts['OT_ma24_scaled'])

print(f"OT_lag1_scaled ã¨ OT_lag24_scaled ã®ç›¸é–¢ä¿‚æ•°: {r1:.3f}")
print(f"OT_lag1_scaled ã¨ OT_ma24_scaled ã®ç›¸é–¢ä¿‚æ•°: {r2:.3f}")
print(f"OT_lag24_scaled ã¨ OT_ma24_scaled ã®ç›¸é–¢ä¿‚æ•°: {r3:.3f}")

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—é †ã«8:2ï¼‰
split_point = int(len(data_fourier_ts) * 0.8)
X2_train, X2_test = X2.iloc[:split_point], X2.iloc[split_point:]
y2_train, y2_test = y2.iloc[:split_point], y2.iloc[split_point:]

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆtrainã®ã¿ï¼‰
model2 = LinearRegression()
model2.fit(X2_train, y2_train)

# äºˆæ¸¬
data_fourier_ts.loc[X2_train.index, 'OT_pred_linear'] = model2.predict(X2_train)
data_fourier_ts.loc[X2_test.index, 'OT_pred_linear'] = model2.predict(X2_test)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
r2_train2 = r2_score(y2_train, data_fourier_ts.loc[X2_train.index, 'OT_pred_linear'])
rmse_train2 = np.sqrt(mean_squared_error(y2_train, data_fourier_ts.loc[X2_train.index, 'OT_pred_linear']))

# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
r2_test2 = r2_score(y2_test, data_fourier_ts.loc[X2_test.index, 'OT_pred_linear'])
rmse_test2 = np.sqrt(mean_squared_error(y2_test, data_fourier_ts.loc[X2_test.index, 'OT_pred_linear']))

print("âœ…  æ™‚ç³»åˆ—8:2åˆ†å‰²")
print(f"ğŸ”¹ RÂ²(è¨“ç·´): {r2_train2:.4f}")
print(f"ğŸ”¹ RMSE(è¨“ç·´): {rmse_train2:.4f}")
print(f"ğŸ”¹ RÂ²(æ¤œè¨¼): {r2_test2:.4f}")
print(f"ğŸ”¹ RMSE(æ¤œè¨¼): {rmse_test2:.4f}")

#%%------------------------------------------
# 5-2 Ridgeå›å¸°åˆ†æ
#--------------------------------------------

# æ®‹å·®ã‚’ä½œæˆï¼ˆä¸€æ¬¡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®èª¤å·®ï¼‰
data_fourier_ts['residual_linear'] = data_fourier_ts['OT_scaled'] - data_fourier_ts['OT_pred_linear']

# ç‰¹å¾´é‡
X2_ridge = data_fourier_ts[['HUFL_scaled', 'HULL_scaled','MUFL_scaled','LUFL_scaled']] #MULL_scaledã¨LULL_scaledã‚’é™¤å¤–
y2_ridge = data_fourier_ts[['residual_linear']]

# æ™‚ç³»åˆ—åˆ†å‰²
split_point = int(len(data_fourier_ts) * 0.8)
X2_train, X2_test = X2_ridge.iloc[:split_point], X2_ridge.iloc[split_point:]
y2_train, y2_test = y2_ridge.iloc[:split_point], y2_ridge.iloc[split_point:]

# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ãƒ»å­¦ç¿’
ridge_model2 = Ridge(alpha=1.0)
ridge_model2.fit(X2_train, y2_train)

# train/test ãã‚Œãã‚Œã§äºˆæ¸¬
data_fourier_ts.loc[X2_train.index, 'OT_pred_residual'] = ridge_model2.predict(X2_train)
data_fourier_ts.loc[X2_test.index, 'OT_pred_residual'] = ridge_model2.predict(X2_test)

# è©•ä¾¡ï¼ˆå‚è€ƒï¼‰
r2_train2   = r2_score(y2_train, data_fourier_ts.loc[X2_train.index, 'OT_pred_residual'])
r2_test2    = r2_score(y2_test, data_fourier_ts.loc[X2_test.index, 'OT_pred_residual'])
rmse_train2 = np.sqrt(mean_squared_error(y2_train, data_fourier_ts.loc[X2_train.index, 'OT_pred_residual']))
rmse_test2  = np.sqrt(mean_squared_error(y2_test, data_fourier_ts.loc[X2_test.index, 'OT_pred_residual']))

print("âœ… Ridgeå›å¸°åˆ†æ2å®Œäº†")
print(f"ğŸ”¹ RÂ²(è¨“ç·´): {r2_train2:.4f}")
print(f"ğŸ”¹ RÂ²(æ¤œè¨¼): {r2_test2:.4f}")
print(f"ğŸ”¹ RMSE(è¨“ç·´): {rmse_train2:.4f}")
print(f"ğŸ”¹ RMSE(æ¤œè¨¼): {rmse_test:.4f}")

#%%------------------------------------------
# 5-3 æœ€çµ‚äºˆæ¸¬å€¤ã®ç®—å‡º
#--------------------------------------------

# å‰åŠ8å‰²ã‚’å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã€å¾ŒåŠ2å‰²ã‚’äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹
# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
split_point2 = int(len(data_fourier_ts) * 0.8)
train2 = data_fourier_ts.iloc[:split_point2].copy()
test2 = data_fourier_ts.iloc[split_point2:].copy()
test2['OT_pred_final'] = test2['OT_pred_linear'] + test2['OT_pred_residual']

#ã€€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
r2_final2 = r2_score(test2['OT_scaled'], test2['OT_pred_final'])
rmse_final2 = np.sqrt(mean_squared_error(test2['OT_scaled'], test2['OT_pred_final']))
mae_final2 = mean_absolute_error(test2['OT_scaled'], test2['OT_pred_final'])

print("âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è©•ä¾¡(æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿2å‰²)å®Œäº†")
print(f"æ±ºå®šä¿‚æ•° RÂ²(æ¤œè¨¼): {r2_final2:.4f}")
print(f"RMSE(æ¤œè¨¼): {rmse_final2:.4f}")
print(f"MAE(æ¤œè¨¼): {mae_final2:.4f}")

#%%------------------------------------------
# 5-4 æœ€çµ‚äºˆæ¸¬å€¤ã®å¯è¦–åŒ–
#--------------------------------------------

plt.figure(figsize=(10, 4))
plt.plot(test2.index, test2['OT_scaled'], label='Actual', linewidth=1)
plt.plot(test2.index, test2['OT_pred_final'], label='Predicted (Final)', linestyle='--', linewidth=1.2)
plt.title('Actual vs Predicted (Final Model)')
plt.xlabel('Date')
plt.ylabel('OT_scaled')
plt.legend()
plt.grid(True)
plt.show()

#%%------------------------------------------
# 5-5 æ®‹å·®ã®æ¨ç§»ã®å¯è¦–åŒ–
#--------------------------------------------

plt.figure(figsize=(10, 3))
plt.plot(test2.index, test2['residual_linear'], label='Residual (Before Ridge)', color='gray', alpha=0.7)
plt.plot(test2.index, test2['OT_pred_residual'], label='Residual (Predicted by Ridge)', color='blue', alpha=0.7)
plt.title('Residuals Before and After Ridge Correction')
plt.xlabel('Date')
plt.ylabel('Residual')
plt.legend()
plt.grid(True)
plt.show()


#%%------------------------------------------
# 5-6 æ®‹å·®ã®è‡ªå·±ç›¸é–¢ãƒ»åè‡ªå·±ç›¸é–¢ã®å¯è¦–åŒ–
#--------------------------------------------

# Ridgeè£œæ­£å¾Œã®æ®‹å·®ã‚’ä½¿ç”¨
residuals2 = data_fourier_ts['OT_pred_residual']  # è‡ªåˆ†ã®åˆ—åã«åˆã‚ã›ã¦å¤‰æ›´ï¼

# ACFï¼ˆè‡ªå·±ç›¸é–¢é–¢æ•°ï¼‰
plt.figure(figsize=(10, 4))
plot_acf(residuals2, lags=50)
plt.title("Autocorrelation Function (ACF) of Residuals")
plt.xlabel("Lag")
plt.ylabel("ACF")
plt.grid(True)
plt.tight_layout()
plt.show()

# PACFï¼ˆåè‡ªå·±ç›¸é–¢é–¢æ•°ï¼‰
plt.figure(figsize=(10, 4))
plot_pacf(residuals2, lags=50, method='ywm')
plt.title("Partial Autocorrelation Function (PACF) of Residuals")
plt.xlabel("Lag")
plt.ylabel("PACF")
plt.grid(True)
plt.tight_layout()
plt.show()

#DWæ¤œå®šã®å®Ÿè¡Œ
from statsmodels.stats.stattools import durbin_watson
dw_stat2 = durbin_watson(data_fourier_ts['residual_linear'])
print('Durbin-Watson æ¤œå®šçµ±è¨ˆé‡:', dw_stat2)


#%%------------------------------------------
# 5-7 ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–
#--------------------------------------------

# ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ•°ã¨æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å›å¸°åˆ†æã®é‡è¦åº¦
coef_linear2 = pd.DataFrame({
    'feature': X2.columns,
    'coefficient': model2.coef_
}).sort_values('coefficient', ascending=False)

print("ğŸ”¹ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã€‘")
print(coef_linear2)

plt.figure(figsize=(6,4))
plt.barh(coef_linear2['feature'], coef_linear2['coefficient'])
plt.title('Linear Regression Coefficients')
plt.xlabel('Coefficient')
plt.gca().invert_yaxis()
plt.show()


# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã®é‡è¦åº¦
coef_ridge2 = pd.DataFrame({
    'feature': X2_ridge.columns,
    'coefficient': ridge_model2.coef_
}).sort_values('coefficient', ascending=False)

print("\nğŸ”¹ã€Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã€‘")
print(coef_ridge2.head()) 

plt.figure(figsize=(8,6))
plt.barh(coef_ridge2['feature'].head(), coef_ridge2['coefficient'].head(15))
plt.title('Ridge Regression Coefficients')
plt.xlabel('Coefficient')
plt.gca().invert_yaxis()
plt.show()

#%%------------------------------------------
# 5-8 å›å¸°ãƒ¢ãƒ‡ãƒ«ã®på€¤ãƒ»æœ‰æ„æ€§ã®ç¢ºèª
#--------------------------------------------
import statsmodels.api as sm
import pandas as pd

# === â‘  ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ•ãƒ¼ãƒªã‚¨ï¼‹æ™‚ç³»åˆ—å¤‰æ•°ï¼‰ ===
X2_train_sm = sm.add_constant(X2_train)  # åˆ‡ç‰‡ã‚’è¿½åŠ 
ols_model2 = sm.OLS(y2_train, X2_train_sm).fit()

print("ğŸ”¹ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼šçµ±è¨ˆçš„è¦ç´„ã€‘")
print(ols_model2.summary())

# ä¸»è¦ãªæŒ‡æ¨™ã ã‘æŠœãå‡ºã™è¡¨
summary_linear2 = pd.DataFrame({
    "feature": ['const'] + list(X2_train.columns),
    "coef": ols_model2.params.values,
    "std_err": ols_model2.bse.values,
    "t_value": ols_model2.tvalues.values,
    "p_value": ols_model2.pvalues.values
})
print("\nã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ« ä¿‚æ•°ãƒ»på€¤ä¸€è¦§ã€‘")
print(summary_linear2.sort_values("p_value").head(10))



# Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«
X2_ridge_sm = sm.add_constant(X2_train)
ols_ridge_like2 = sm.OLS(y2_train, X2_ridge_sm).fit()

print("\nğŸ”¹ã€Ridgeå›å¸°ãƒ¢ãƒ‡ãƒ«ç›¸å½“ã®çµ±è¨ˆè¦ç´„ã€‘")
print(ols_ridge_like2.summary())

summary_ridge2 = pd.DataFrame({
    "feature": ['const'] + list(X2_train.columns),
    "coef": ols_ridge_like2.params.values,
    "std_err": ols_ridge_like2.bse.values,
    "t_value": ols_ridge_like2.tvalues.values,
    "p_value": ols_ridge_like2.pvalues.values
})
print("\nã€Ridgeç›¸å½“ãƒ¢ãƒ‡ãƒ« ä¿‚æ•°ãƒ»på€¤ä¸€è¦§ã€‘")
print(summary_ridge2.sort_values("p_value").head())
#%%
